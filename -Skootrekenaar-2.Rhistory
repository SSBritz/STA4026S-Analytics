#Simulated data
x <- runif(100, -2, 2)
y <- x + 2*cos(5*x) + rnorm(100, sd = sqrt(2))
#The true function
xx <- seq(-2, 2, length.out = 1000)
f <- xx + 2*cos(5*xx)
#Fit cubic splines with increasing degrees of freedom
for(dof in 2:50){
fhat <- smooth.spline(x, y, df = dof)
plot(x, y, pch = 16)
lines(xx, f, 'l', lwd = 2)
lines(fhat, col = 'blue', lwd = 2)
title(main = paste('Degrees of freedom:', dof))
legend('bottomright', c('f(x) - True', expression(hat(f)(x) ~ '- Cubic spline')),
col = c('black', 'blue'), lty = 1, lwd = 2)
}
set.seed(4026)
n <- 100        #Sample size
num_sims <- 1000#Number of iterations
dofs <- 10:35    #Model complexities
pred_mat <- matrix(nrow = num_sims, ncol = n) #To store each set of predictions
mses <- vector(length = num_sims)     #Also want to track the testing MSEs
red_err <- vector(length = num_sims)  #As well as the reducible error
#Herein we will capture the deconstructed components for each model
results <- matrix(nrow = length(dofs), ncol = 4)
colnames(results) <- c('Var', 'Bias2', 'Red_err', 'MSE')
#Testing data
x_test <- runif(n, -2, 2)
f_test <- x_test + 2*cos(5*x_test) #This is the part we don't know outside sims!!
y_test <- f_test + rnorm(n, sd = sqrt(2))
d <- 0 #To keep track of dof iterations, whilst easily changing the range above
for(dof in dofs) { #Repeat over all model complexities
d <- d+1
for(iter in 1:num_sims){
#Training data
x_train <- runif(n, -2, 2)
y_train <- x_train + 2*cos(5*x_train) + rnorm(n, sd = sqrt(2))
#Fit cubic spline
spline_mod <- smooth.spline(x_train, y_train, df = dof)
#Predict on OOS data
yhat <- predict(spline_mod, x_test)$y
#And store
pred_mat[iter, ] <- yhat
red_err[iter] <- mean((f_test - yhat)^2)
mses[iter] <- mean((y_test - yhat)^2)
}
var_fhat <- mean(apply(pred_mat, 2, var)) #E[\hat{f} - E(\hat{f})]^2
bias2_fhat <- mean((colMeans(pred_mat) - f_test)^2) #[E(\hat{f}) - f]^2
reducible <- mean(red_err) #E[f - \hat{f}]^2
MSE <- mean(mses)          #E[y_0 - \hat{f}]^2
results[d, ] <- c(var_fhat, bias2_fhat, reducible, MSE)
}
#Plot the results
plot(dofs, results[, 2], 'l', col = 'lightblue', lwd = 2,
xlab = 'Model complexity', ylab = '', ylim = c(0, max(results[,-4])))
lines(dofs, results[, 1], 'l', col = 'orange', lwd = 2)
lines(dofs, results[, 3], 'l', col = 'darkred', lwd = 2)
abline(v = dofs[which.min(results[, 3])])
lines(dofs, results[, 4], 'l', lwd = 2)
View(results)
set.seed(4026)
#Simulated data
x <- runif(100, -2, 2)
y <- x + 2*cos(5*x) + rnorm(100, sd = sqrt(2))
#The true function
xx <- seq(-2, 2, length.out = 1000)
f <- xx + 2*cos(5*xx)
#Fit cubic splines with increasing degrees of freedom
for(dof in 2:50){
fhat <- smooth.spline(x, y, df = dof)
plot(x, y, pch = 16)
lines(xx, f, 'l', lwd = 2)
lines(fhat, col = 'blue', lwd = 2)
title(main = paste('Degrees of freedom:', dof))
legend('bottomright', c('f(x) - True', expression(hat(f)(x) ~ '- Cubic spline')),
col = c('black', 'blue'), lty = 1, lwd = 2)
}
set.seed(4026)
n <- 100        #Sample size
num_sims <- 1000#Number of iterations
dofs <- 2:19    #Model complexities
pred_mat <- matrix(nrow = num_sims, ncol = n) #To store each set of predictions
mses <- vector(length = num_sims)     #Also want to track the testing MSEs
red_err <- vector(length = num_sims)  #As well as the reducible error
#Herein we will capture the deconstructed components for each model
results <- matrix(nrow = length(dofs), ncol = 4)
colnames(results) <- c('Var', 'Bias2', 'Red_err', 'MSE')
#Testing data
x_test <- runif(n, -2, 2)
f_test <- x_test + 2*cos(5*x_test) #This is the part we don't know outside sims!!
y_test <- f_test + rnorm(n, sd = sqrt(2))
d <- 0 #To keep track of dof iterations, whilst easily changing the range above
for(dof in dofs) { #Repeat over all model complexities
d <- d+1
for(iter in 1:num_sims){
#Training data
x_train <- runif(n, -2, 2)
y_train <- x_train + 2*cos(5*x_train) + rnorm(n, sd = sqrt(2))
#Fit cubic spline
spline_mod <- smooth.spline(x_train, y_train, df = dof)
#Predict on OOS data
yhat <- predict(spline_mod, x_test)$y
#And store
pred_mat[iter, ] <- yhat
red_err[iter] <- mean((f_test - yhat)^2)
mses[iter] <- mean((y_test - yhat)^2)
}
var_fhat <- mean(apply(pred_mat, 2, var)) #E[\hat{f} - E(\hat{f})]^2
bias2_fhat <- mean((colMeans(pred_mat) - f_test)^2) #[E(\hat{f}) - f]^2
reducible <- mean(red_err) #E[f - \hat{f}]^2
MSE <- mean(mses)          #E[y_0 - \hat{f}]^2
results[d, ] <- c(var_fhat, bias2_fhat, reducible, MSE)
}
#Plot the results
plot(dofs, results[, 2], 'l', col = 'lightblue', lwd = 2,
xlab = 'Model complexity', ylab = '', ylim = c(0, max(results[,-4])))
lines(dofs, results[, 1], 'l', col = 'orange', lwd = 2)
lines(dofs, results[, 3], 'l', col = 'darkred', lwd = 2)
abline(v = dofs[which.min(results[, 3])])
lines(dofs, results[, 4], 'l', lwd = 2)
View(results)
set.seed(4026)
#Simulated data
x <- runif(100, -2, 2)
y <- x + 2*cos(5*x) + rnorm(100, sd = sqrt(2))
#The true function
xx <- seq(-2, 2, length.out = 1000)
f <- xx + 2*cos(5*xx)
#Fit cubic splines with increasing degrees of freedom
for(dof in 2:50){
fhat <- smooth.spline(x, y, df = dof)
plot(x, y, pch = 16)
lines(xx, f, 'l', lwd = 2)
lines(fhat, col = 'blue', lwd = 2)
title(main = paste('Degrees of freedom:', dof))
legend('bottomright', c('f(x) - True', expression(hat(f)(x) ~ '- Cubic spline')),
col = c('black', 'blue'), lty = 1, lwd = 2)
}
set.seed(1)
n <- 100        #Sample size
num_sims <- 1000#Number of iterations
dofs <- 2:19    #Model complexities
pred_mat <- matrix(nrow = num_sims, ncol = n) #To store each set of predictions
mses <- vector(length = num_sims)     #Also want to track the testing MSEs
red_err <- vector(length = num_sims)  #As well as the reducible error
#Herein we will capture the deconstructed components for each model
results <- matrix(nrow = length(dofs), ncol = 4)
colnames(results) <- c('Var', 'Bias2', 'Red_err', 'MSE')
#Testing data
x_test <- runif(n, -2, 2)
f_test <- x_test + 2*cos(5*x_test) #This is the part we don't know outside sims!!
y_test <- f_test + rnorm(n, sd = sqrt(2))
d <- 0 #To keep track of dof iterations, whilst easily changing the range above
for(dof in dofs) { #Repeat over all model complexities
d <- d+1
for(iter in 1:num_sims){
#Training data
x_train <- runif(n, -2, 2)
y_train <- x_train + 2*cos(5*x_train) + rnorm(n, sd = sqrt(2))
#Fit cubic spline
spline_mod <- smooth.spline(x_train, y_train, df = dof)
#Predict on OOS data
yhat <- predict(spline_mod, x_test)$y
#And store
pred_mat[iter, ] <- yhat
red_err[iter] <- mean((f_test - yhat)^2)
mses[iter] <- mean((y_test - yhat)^2)
}
var_fhat <- mean(apply(pred_mat, 2, var)) #E[\hat{f} - E(\hat{f})]^2
bias2_fhat <- mean((colMeans(pred_mat) - f_test)^2) #[E(\hat{f}) - f]^2
reducible <- mean(red_err) #E[f - \hat{f}]^2
MSE <- mean(mses)          #E[y_0 - \hat{f}]^2
results[d, ] <- c(var_fhat, bias2_fhat, reducible, MSE)
}
#Plot the results
plot(dofs, results[, 2], 'l', col = 'lightblue', lwd = 2,
xlab = 'Model complexity', ylab = '', ylim = c(0, max(results[,-4])))
lines(dofs, results[, 1], 'l', col = 'orange', lwd = 2)
lines(dofs, results[, 3], 'l', col = 'darkred', lwd = 2)
abline(v = dofs[which.min(results[, 3])])
lines(dofs, results[, 4], 'l', lwd = 2)
View(results)
?lines
plot(dofs, results[, 2], 'l', col = 'lightblue', lwd = 2,
xlab = 'Model complexity', ylab = '', ylim = c(0, max(results[,-4])))
lines(dofs, results[, 1], 'l', col = 'orange', lwd = 2)
lines(dofs, results[, 3], 'l', col = 'darkred', lwd = 2)
abline(v = dofs[which.min(results[, 3])])
lines(dofs, results[, 4], 'l', lwd = 2, type = 2)
plot(dofs, results[, 2], 'l', col = 'lightblue', lwd = 2,
xlab = 'Model complexity', ylab = '', ylim = c(0, max(results[,-4])))
lines(dofs, results[, 1], 'l', col = 'orange', lwd = 2)
lines(dofs, results[, 3], 'l', col = 'darkred', lwd = 2)
abline(v = dofs[which.min(results[, 3])])
lines(dofs, results[, 4], 'l', lwd = 2, type = '-')
plot(dofs, results[, 2], 'l', col = 'lightblue', lwd = 2,
xlab = 'Model complexity', ylab = '', ylim = c(0, max(results[,-4])))
lines(dofs, results[, 1], 'l', col = 'orange', lwd = 2)
lines(dofs, results[, 3], 'l', col = 'darkred', lwd = 2)
abline(v = dofs[which.min(results[, 3])])
lines(dofs, results[, 4], 'l', lwd = 2, type = '1')
plot(dofs, results[, 2], 'l', col = 'lightblue', lwd = 2,
xlab = 'Model complexity', ylab = '', ylim = c(0, max(results[,-4])))
lines(dofs, results[, 1], 'l', col = 'orange', lwd = 2)
lines(dofs, results[, 3], 'l', col = 'darkred', lwd = 2)
abline(v = dofs[which.min(results[, 3])])
lines(dofs, results[, 4], 'l', lwd = 2, lty = 2)
plot(dofs, results[, 2], 'l', col = 'lightblue', lwd = 2,
xlab = 'Model complexity', ylab = '', ylim = c(0, max(results[,-4])))
lines(dofs, results[, 1], 'l', col = 'orange', lwd = 2)
lines(dofs, results[, 3], 'l', col = 'darkred', lwd = 2)
abline(v = dofs[which.min(results[, 3])])
lines(dofs, results[, 4], 'l', lwd = 2, lty = 1)
plot(dofs, results[, 2], 'l', col = 'lightblue', lwd = 2,
xlab = 'Model complexity', ylab = '', ylim = c(0, max(results[,-4])))
lines(dofs, results[, 1], 'l', col = 'orange', lwd = 2)
lines(dofs, results[, 3], 'l', col = 'darkred', lwd = 2)
abline(v = dofs[which.min(results[, 3])], lty = 2)
?data.frame
results <- data.frame(Var = NA, Bias2 = NA, Red_err = NA, MSE = NA)
set.seed(123)
n <- 100        #Sample size
num_sims <- 1000#Number of iterations
dofs <- 2:19    #Model complexities
pred_mat <- matrix(nrow = num_sims, ncol = n) #To store each set of predictions
mses <- vector(length = num_sims)     #Also want to track the testing MSEs
red_err <- vector(length = num_sims)  #As well as the reducible error
#Herein we will capture the deconstructed components for each model
# results <- matrix(nrow = length(dofs), ncol = 4)
# colnames(results) <- c('Var', 'Bias2', 'Red_err', 'MSE')
results <- data.frame(Var = NA, Bias2 = NA, Red_err = NA, MSE = NA)
#Testing data
x_test <- runif(n, -2, 2)
f_test <- x_test + 2*cos(5*x_test) #This is the part we don't know outside sims!!
y_test <- f_test + rnorm(n, sd = sqrt(2))
d <- 0 #To keep track of dof iterations, whilst easily changing the range above
for(dof in dofs) { #Repeat over all model complexities
d <- d+1
for(iter in 1:num_sims){
#Training data
x_train <- runif(n, -2, 2)
y_train <- x_train + 2*cos(5*x_train) + rnorm(n, sd = sqrt(2))
#Fit cubic spline
spline_mod <- smooth.spline(x_train, y_train, df = dof)
#Predict on OOS data
yhat <- predict(spline_mod, x_test)$y
#And store
pred_mat[iter, ] <- yhat
red_err[iter] <- mean((f_test - yhat)^2)
mses[iter] <- mean((y_test - yhat)^2)
}
var_fhat <- mean(apply(pred_mat, 2, var)) #E[\hat{f} - E(\hat{f})]^2
bias2_fhat <- mean((colMeans(pred_mat) - f_test)^2) #[E(\hat{f}) - f]^2
reducible <- mean(red_err) #E[f - \hat{f}]^2
MSE <- mean(mses)          #E[y_0 - \hat{f}]^2
results[d, ] <- c(var_fhat, bias2_fhat, reducible, MSE)
}
View(results)
plot(dofs, results$Var, 'l', col = 'orange', lwd = 2,
xlab = 'Model complexity', ylab = '', ylim = c(0, max(results[,-4])))
plot(dofs, results$Var, 'l', col = 'orange', lwd = 2,
xlab = 'Model complexity', ylab = '', ylim = c(0, max(results[,-4])))
lines(dofs, results$Bias2, 'l', col = 'lightblue', lwd = 2)
lines(dofs, results$Red_err, 'l', col = 'darkred', lwd = 2)
abline(v = dofs[which.min(results$Red_err)], lty = 2)
set.seed(4026)
#Simulated data
x <- runif(100, -2, 2)
y <- x + 2*cos(5*x) + rnorm(100, sd = sqrt(2))
#The true function
xx <- seq(-2, 2, length.out = 1000)
f <- xx + 2*cos(5*xx)
#Fit cubic splines with increasing degrees of freedom
for(dof in 2:50){
fhat <- smooth.spline(x, y, df = dof)
plot(x, y, pch = 16)
lines(xx, f, 'l', lwd = 2)
lines(fhat, col = 'blue', lwd = 2)
title(main = paste('Degrees of freedom:', dof))
legend('bottomright', c('f(x) - True', expression(hat(f)(x) ~ '- Cubic spline')),
col = c('black', 'blue'), lty = 1, lwd = 2)
}
set.seed(123)
n <- 100        #Sample size
num_sims <- 1000#Number of iterations
dofs <- 2:19    #Model complexities
pred_mat <- matrix(nrow = num_sims, ncol = n) #To store each set of predictions
mses <- vector(length = num_sims)     #Also want to track the testing MSEs
red_err <- vector(length = num_sims)  #As well as the reducible error
#Herein we will capture the deconstructed components for each model
results <- data.frame(Var = NA, Bias2 = NA, Red_err = NA, MSE = NA)
#Testing data
x_test <- runif(n, -2, 2)
f_test <- x_test + 2*cos(5*x_test) #This is the part we don't know outside sims!!
y_test <- f_test + rnorm(n, sd = sqrt(2))
d <- 0 #To keep track of dof iterations, whilst easily changing the range above
for(dof in dofs) { #Repeat over all model complexities
d <- d+1
for(iter in 1:num_sims){
#Training data
x_train <- runif(n, -2, 2)
y_train <- x_train + 2*cos(5*x_train) + rnorm(n, sd = sqrt(2))
#Fit cubic spline
spline_mod <- smooth.spline(x_train, y_train, df = dof)
#Predict on OOS data
yhat <- predict(spline_mod, x_test)$y
#And store
pred_mat[iter, ] <- yhat
red_err[iter] <- mean((f_test - yhat)^2)
mses[iter] <- mean((y_test - yhat)^2)
}
var_fhat <- mean(apply(pred_mat, 2, var)) #E[\hat{f} - E(\hat{f})]^2
bias2_fhat <- mean((colMeans(pred_mat) - f_test)^2) #[E(\hat{f}) - f]^2
reducible <- mean(red_err) #E[f - \hat{f}]^2
MSE <- mean(mses)          #E[y_0 - \hat{f}]^2
results[d, ] <- c(var_fhat, bias2_fhat, reducible, MSE)
}
#Plot the results
plot(dofs, results$Var, 'l', col = 'orange', lwd = 2,
xlab = 'Model complexity', ylab = '', ylim = c(0, max(results[,-4])))
lines(dofs, results$Bias2, 'l', col = 'lightblue', lwd = 2)
lines(dofs, results$Red_err, 'l', col = 'darkred', lwd = 2)
abline(v = dofs[which.min(results$Red_err)], lty = 2)
# lines(dofs, results[, 4], 'l', lwd = 2)
View(results)
set.seed(4026)
#Simulated data
x <- runif(100, -2, 2)
y <- x + 2*cos(5*x) + rnorm(100, sd = sqrt(2))
#The true function
xx <- seq(-2, 2, length.out = 1000)
f <- xx + 2*cos(5*xx)
#Fit cubic splines with increasing degrees of freedom
for(dof in 2:50){
fhat <- smooth.spline(x, y, df = dof)
plot(x, y, pch = 16)
lines(xx, f, 'l', lwd = 2)
lines(fhat, col = 'blue', lwd = 2)
title(main = paste('Degrees of freedom:', dof))
legend('bottomright', c('f(x) - True', expression(hat(f)(x) ~ '- Cubic spline')),
col = c('black', 'blue'), lty = 1, lwd = 2)
}
set.seed(123)
n <- 100        #Sample size
num_sims <- 1000#Number of iterations
dofs <- 3    #Model complexities
pred_mat <- matrix(nrow = num_sims, ncol = n) #To store each set of predictions
mses <- vector(length = num_sims)     #Also want to track the testing MSEs
red_err <- vector(length = num_sims)  #As well as the reducible error
#Herein we will capture the deconstructed components for each model
results <- data.frame(Var = NA, Bias2 = NA, Red_err = NA, MSE = NA)
#Testing data
x_test <- runif(n, -2, 2)
f_test <- x_test + 2*cos(5*x_test) #This is the part we don't know outside sims!!
y_test <- f_test + rnorm(n, sd = sqrt(2))
d <- 0 #To keep track of dof iterations, whilst easily changing the range above
for(dof in dofs) { #Repeat over all model complexities
d <- d+1
for(iter in 1:num_sims){
#Training data
x_train <- runif(n, -2, 2)
y_train <- x_train + 2*cos(5*x_train) + rnorm(n, sd = sqrt(2))
#Fit cubic spline
spline_mod <- smooth.spline(x_train, y_train, df = dof)
#Predict on OOS data
yhat <- predict(spline_mod, x_test)$y
#And store
pred_mat[iter, ] <- yhat
red_err[iter] <- mean((f_test - yhat)^2)
mses[iter] <- mean((y_test - yhat)^2)
}
var_fhat <- mean(apply(pred_mat, 2, var)) #E[\hat{f} - E(\hat{f})]^2
bias2_fhat <- mean((colMeans(pred_mat) - f_test)^2) #[E(\hat{f}) - f]^2
reducible <- mean(red_err) #E[f - \hat{f}]^2
MSE <- mean(mses)          #E[y_0 - \hat{f}]^2
results[d, ] <- c(var_fhat, bias2_fhat, reducible, MSE)
}
#Plot the results
plot(dofs, results$Var, 'l', col = 'orange', lwd = 2,
xlab = 'Model complexity', ylab = '', ylim = c(0, max(results[,-4])))
lines(dofs, results$Bias2, 'l', col = 'lightblue', lwd = 2)
lines(dofs, results$Red_err, 'l', col = 'darkred', lwd = 2)
abline(v = dofs[which.min(results$Red_err)], lty = 2)
# lines(dofs, results[, 4], 'l', lwd = 2)
set.seed(4026)
#Simulated data
x <- runif(100, -2, 2)
y <- x + 2*cos(5*x) + rnorm(100, sd = sqrt(2))
#The true function
xx <- seq(-2, 2, length.out = 1000)
f <- xx + 2*cos(5*xx)
#Fit cubic splines with increasing degrees of freedom
for(dof in 2:50){
fhat <- smooth.spline(x, y, df = dof)
plot(x, y, pch = 16)
lines(xx, f, 'l', lwd = 2)
lines(fhat, col = 'blue', lwd = 2)
title(main = paste('Degrees of freedom:', dof))
legend('bottomright', c('f(x) - True', expression(hat(f)(x) ~ '- Cubic spline')),
col = c('black', 'blue'), lty = 1, lwd = 2)
}
set.seed(123)
n <- 100        #Sample size
num_sims <- 1000#Number of iterations
dofs <- 3:4    #Model complexities
pred_mat <- matrix(nrow = num_sims, ncol = n) #To store each set of predictions
mses <- vector(length = num_sims)     #Also want to track the testing MSEs
red_err <- vector(length = num_sims)  #As well as the reducible error
#Herein we will capture the deconstructed components for each model
results <- data.frame(Var = NA, Bias2 = NA, Red_err = NA, MSE = NA)
#Testing data
x_test <- runif(n, -2, 2)
f_test <- x_test + 2*cos(5*x_test) #This is the part we don't know outside sims!!
y_test <- f_test + rnorm(n, sd = sqrt(2))
d <- 0 #To keep track of dof iterations, whilst easily changing the range above
for(dof in dofs) { #Repeat over all model complexities
d <- d+1
for(iter in 1:num_sims){
#Training data
x_train <- runif(n, -2, 2)
y_train <- x_train + 2*cos(5*x_train) + rnorm(n, sd = sqrt(2))
#Fit cubic spline
spline_mod <- smooth.spline(x_train, y_train, df = dof)
#Predict on OOS data
yhat <- predict(spline_mod, x_test)$y
#And store
pred_mat[iter, ] <- yhat
red_err[iter] <- mean((f_test - yhat)^2)
mses[iter] <- mean((y_test - yhat)^2)
}
var_fhat <- mean(apply(pred_mat, 2, var)) #E[\hat{f} - E(\hat{f})]^2
bias2_fhat <- mean((colMeans(pred_mat) - f_test)^2) #[E(\hat{f}) - f]^2
reducible <- mean(red_err) #E[f - \hat{f}]^2
MSE <- mean(mses)          #E[y_0 - \hat{f}]^2
results[d, ] <- c(var_fhat, bias2_fhat, reducible, MSE)
}
#Plot the results
plot(dofs, results$Var, 'l', col = 'orange', lwd = 2,
xlab = 'Model complexity', ylab = '', ylim = c(0, max(results[,-4])))
lines(dofs, results$Bias2, 'l', col = 'lightblue', lwd = 2)
lines(dofs, results$Red_err, 'l', col = 'darkred', lwd = 2)
abline(v = dofs[which.min(results$Red_err)], lty = 2)
# lines(dofs, results[, 4], 'l', lwd = 2)
View(results)
View(pred_mat)
View(pred_mat)
apply(pred_mat, 2, var)
max(pred_mat)
wtf <- pred_mat[, 35]
max(wtf)
var(wtf)
plot(1:1000, wtf)
set.seed(4026)
#Simulated data
x <- runif(100, -2, 2)
y <- x + 2*cos(5*x) + rnorm(100, sd = sqrt(2))
#The true function
xx <- seq(-2, 2, length.out = 1000)
f <- xx + 2*cos(5*xx)
#Fit cubic splines with increasing degrees of freedom
for(dof in 2:50){
fhat <- smooth.spline(x, y, df = dof)
plot(x, y, pch = 16)
lines(xx, f, 'l', lwd = 2)
lines(fhat, col = 'blue', lwd = 2)
title(main = paste('Degrees of freedom:', dof))
legend('bottomright', c('f(x) - True', expression(hat(f)(x) ~ '- Cubic spline')),
col = c('black', 'blue'), lty = 1, lwd = 2)
}
set.seed(1)
n <- 100        #Sample size
num_sims <- 1000#Number of iterations
dofs <- 2:24    #Model complexities
pred_mat <- matrix(nrow = num_sims, ncol = n) #To store each set of predictions
mses <- vector(length = num_sims)     #Also want to track the testing MSEs
red_err <- vector(length = num_sims)  #As well as the reducible error
#Herein we will capture the deconstructed components for each model
results <- data.frame(Var = NA, Bias2 = NA, Red_err = NA, MSE = NA)
#Testing data
x_test <- runif(n, -2, 2)
f_test <- x_test + 2*cos(5*x_test) #This is the part we don't know outside sims!!
y_test <- f_test + rnorm(n, sd = sqrt(2))
d <- 0 #To keep track of dof iterations, whilst easily changing the range above
for(dof in dofs) { #Repeat over all model complexities
d <- d+1
for(iter in 1:num_sims){
#Training data
x_train <- runif(n, -2, 2)
y_train <- x_train + 2*cos(5*x_train) + rnorm(n, sd = sqrt(2))
#Fit cubic spline
spline_mod <- smooth.spline(x_train, y_train, df = dof)
#Predict on OOS data
yhat <- predict(spline_mod, x_test)$y
#And store
pred_mat[iter, ] <- yhat
red_err[iter] <- mean((f_test - yhat)^2)
mses[iter] <- mean((y_test - yhat)^2)
}
var_fhat <- mean(apply(pred_mat, 2, var)) #E[\hat{f} - E(\hat{f})]^2
bias2_fhat <- mean((colMeans(pred_mat) - f_test)^2) #[E(\hat{f}) - f]^2
reducible <- mean(red_err) #E[f - \hat{f}]^2
MSE <- mean(mses)          #E[y_0 - \hat{f}]^2
results[d, ] <- c(var_fhat, bias2_fhat, reducible, MSE)
}
#Plot the results
plot(dofs, results$Var, 'l', col = 'orange', lwd = 2,
xlab = 'Model complexity', ylab = '', ylim = c(0, max(results[,-4])))
lines(dofs, results$Bias2, 'l', col = 'lightblue', lwd = 2)
lines(dofs, results$Red_err, 'l', col = 'darkred', lwd = 2)
abline(v = dofs[which.min(results$Red_err)], lty = 2)
# lines(dofs, results[, 4], 'l', lwd = 2)
bookdown::render_book("index.Rmd")
